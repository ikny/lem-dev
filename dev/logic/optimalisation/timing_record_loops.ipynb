{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing ```04_record_loops``` using ```timeit``` module\n",
    "Firstly, lets initialize all the necessary variables, as that is not something I have to time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import numpy.typing as npt\n",
    "\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import threading\n",
    "import random\n",
    "import timeit\n",
    "\n",
    "\n",
    "SAMPLERATE = 44100  # [samples per second]\n",
    "BLOCKSIZE = 1000  # [samples]\n",
    "DTYPE = np.int16\n",
    "STR_DTYPE = \"int16\"\n",
    "CHANNELS = 2\n",
    "LATENCY = 0\n",
    "\n",
    "METRONOME_SAMPLE_PATH = \"lib/samples/metronome.wav\"\n",
    "\n",
    "recording = False\n",
    "stream_active = True\n",
    "\n",
    "tracks: list[npt.NDArray[DTYPE]] = []\n",
    "recorded_track: npt.NDArray[DTYPE] = np.empty(shape=(0, CHANNELS), dtype=DTYPE)\n",
    "current_frame = 0\n",
    "len_beat: int  # number of samples per beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is questionable whether some of these could be optimalised. E.g. using numpy array instead of list for ```tracks``` could be faster. However, different tracks need to differ in length and I do not know whether numpy allows this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets analyze the functions in the program. There are three groups of functions:\n",
    "- ```metronome_generator``` and ```initialize_metronome```, which execute before the body of the program,\n",
    "- ```input_checker``` and ```post_production```, which are executed in the input thread,\n",
    "-  ```main``` and ```callback```, which are executed in the thread which is processing audio.\n",
    "\n",
    "As the first ones do not need to be timed, lets execute them now so the other ones can use the metronome sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metronome_generator(bpm: int, path: str) -> npt.NDArray[DTYPE]:\n",
    "    global len_beat\n",
    "\n",
    "    sample: npt.NDArray[DTYPE]\n",
    "    sample, fs = sf.read(file=path, dtype=STR_DTYPE)\n",
    "\n",
    "    desired_len = int((60*fs)/bpm)\n",
    "    len_beat = desired_len\n",
    "\n",
    "    if len(sample) <= desired_len:\n",
    "        # rounding desired_len introduces a distortion of bpm\n",
    "        sample = np.concatenate(\n",
    "            (sample, np.zeros(shape=(desired_len-len(sample), CHANNELS), dtype=DTYPE)))\n",
    "    else:\n",
    "        sample = sample[:desired_len]\n",
    "\n",
    "    # adjust volume\n",
    "    sample = (sample/4).astype(dtype=DTYPE)\n",
    "\n",
    "    return sample\n",
    "\n",
    "\n",
    "def initialize_metronome() -> None:\n",
    "    global tracks\n",
    "    # initialize metronome\n",
    "    bpm = int(input(\"bpm: \"))\n",
    "    metronome = metronome_generator(bpm=bpm, path=METRONOME_SAMPLE_PATH)\n",
    "    tracks.append(metronome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other two groups run in the same thread, for python does not allow true parallelism, so it is necessary to optimalise both of them. Lets start with the audio processing, as I suppose it may require more CPU power and I also have some ideas for optimalisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    \"\"\" processes the audio \"\"\"\n",
    "    global stream_active\n",
    "\n",
    "    def callback(indata: npt.NDArray[DTYPE], outdata: npt.NDArray[DTYPE],\n",
    "                 frames: int, time: Any, status: sd.CallbackFlags) -> None:\n",
    "        global current_frame\n",
    "        global tracks\n",
    "        global recorded_track\n",
    "\n",
    "        if status:\n",
    "            print(status)\n",
    "\n",
    "        if recording:\n",
    "            recorded_track = np.concatenate([recorded_track, indata])\n",
    "\n",
    "        # mixer & slicer\n",
    "        num_tracks = len(tracks)\n",
    "        data = (indata/(num_tracks + 1)).astype(dtype=DTYPE)\n",
    "\n",
    "        for track in tracks:\n",
    "            # slice\n",
    "            start = current_frame % len(track)\n",
    "            end = (current_frame+frames) % len(track)\n",
    "            if end < start:\n",
    "                track_slice = np.concatenate(\n",
    "                    (track[start:], track[:end]))\n",
    "            else:\n",
    "                track_slice = track[start:end]\n",
    "            # mix\n",
    "            track_slice = (track_slice/(num_tracks+1)).astype(dtype=DTYPE)\n",
    "\n",
    "            data += track_slice\n",
    "\n",
    "        outdata[:] = data\n",
    "        current_frame += frames\n",
    "\n",
    "    try:\n",
    "        with sd.Stream(samplerate=SAMPLERATE, blocksize=BLOCKSIZE, dtype=STR_DTYPE,\n",
    "                       channels=CHANNELS, callback=callback):\n",
    "            while stream_active:\n",
    "                pass\n",
    "    finally:\n",
    "        print(\"Good bye!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas:\n",
    "- is using global variables slow?\n",
    "- the for loop is certainly inefficient -> use numpy.mean() for the mixing\n",
    "    - how to improve the cutting?\n",
    "- is the handling of large integers in ```current_frame``` okay?\n",
    "- is the while loop, which is keeping the stream active, draining CPU power? If yes, how to keep the stream alive without this drawback?\n",
    "\n",
    "First of all, mixing and cutting. Or just mixing, as it is a smaller piece of code. Lets initialize some track data, so we can test different approaches:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN_TRACK = 100\n",
    "NUM_TRACKS = 10\n",
    "NUMBER = 1\n",
    "REPEAT = 10000\n",
    "\n",
    "def generate_random_track(length: int, channels: int = 2) -> npt.NDArray[DTYPE]:\n",
    "    return np.array([[random.randint(-2**15, 2**15-1), random.randint(-2**15, 2**15-1)] for i in range(length)])\n",
    "\n",
    "cut_tracks = np.array([generate_random_track(LEN_TRACK) for i in range(NUM_TRACKS)])\n",
    "\n",
    "for_loop = \"\"\"\n",
    "data = cut_tracks[0]\n",
    "for track_slice in cut_tracks:\n",
    "    track_slice = (track_slice/(NUM_TRACKS+1)).astype(dtype=DTYPE)\n",
    "    data += track_slice\"\"\"\n",
    "\n",
    "np_mean = \"\"\"\n",
    "data = np.mean(a=cut_tracks, axis=0)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can comparte those two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.mean was 0.0001272629997401964 second faster\n"
     ]
    }
   ],
   "source": [
    "for_loop_time = min(timeit.repeat(stmt=for_loop, number=NUMBER, repeat=REPEAT, globals=globals()))\n",
    "mean_time = min(timeit.repeat(stmt=np_mean, number=NUMBER, repeat=REPEAT, globals=globals()))\n",
    "\n",
    "difference = for_loop_time - mean_time\n",
    "if difference < 0:\n",
    "    print(f\"for loop was {difference*-1} second faster\")\n",
    "else:\n",
    "    print(f\"np.mean was {difference} second faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In january I have figured out that I store the recorded tracks in a `list` of `np.arrays`. I am wondering whether it would be faster to store them in a big `np.array`, so lets time it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_matrix = np.array([generate_random_track(length=LEN_TRACK) for i in range(NUM_TRACKS)])\n",
    "big_list = [generate_random_track(length=LEN_TRACK) for i in range(NUM_TRACKS)]\n",
    "\n",
    "# averaging a list with for loop\n",
    "for_loop_list = \"\"\"\n",
    "data = big_list[0]\n",
    "for track_slice in big_list:\n",
    "    track_slice = (track_slice/(NUM_TRACKS+1)).astype(dtype=DTYPE)\n",
    "    data += track_slice\n",
    "\"\"\"\n",
    "\n",
    "# averaging an array with for loop\n",
    "for_loop_matrix = \"\"\"\n",
    "data = np_matrix[0]\n",
    "for track_slice in np_matrix:\n",
    "    track_slice = (track_slice/(NUM_TRACKS+1)).astype(dtype=DTYPE)\n",
    "    data += track_slice\n",
    "\"\"\"\n",
    "\n",
    "# averaging a list with np.mean\n",
    "np_mean_list = \"\"\"\n",
    "data = np.mean(a=big_list, axis=0)\n",
    "\"\"\"\n",
    "\n",
    "# averaging an array with np.mean\n",
    "np_mean_matrix = \"\"\"\n",
    "data = np.mean(a=np_matrix, axis=0)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time of averaging a list with for loop:      0.00015654699996048294 s\n",
      "time of averaging an array with for loop:    0.00016584100012551062 s\n",
      "time of averaging a list with np.mean:       5.441300004349614e-05 s\n",
      "time of averaging an array with np.mean:     3.953800000999763e-05 s\n"
     ]
    }
   ],
   "source": [
    "for_loop_list_time = min(timeit.repeat(stmt=for_loop_list, number=NUMBER, repeat=REPEAT, globals=globals()))\n",
    "for_loop_matrix_time = min(timeit.repeat(stmt=for_loop_matrix, number=NUMBER, repeat=REPEAT, globals=globals()))\n",
    "np_mean_list_time = min(timeit.repeat(stmt=np_mean_list, number=NUMBER, repeat=REPEAT, globals=globals()))\n",
    "np_mean_matrix_time = min(timeit.repeat(stmt=np_mean_matrix, number=NUMBER, repeat=REPEAT, globals=globals()))\n",
    "\n",
    "print(f\"time of averaging a list with for loop:      {for_loop_list_time} s\")\n",
    "print(f\"time of averaging an array with for loop:    {for_loop_matrix_time} s\")\n",
    "print(f\"time of averaging a list with np.mean:       {np_mean_list_time} s\")\n",
    "print(f\"time of averaging an array with np.mean:     {np_mean_matrix_time} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "averaging an array with np.mean is: \n",
      "      3.959406138927064 times faster than averaging a list with for loop (my current practice)\n",
      "averaging a list with np.mean is: \n",
      "      2.8770146809649146 times faster than averaging a list with for loop (my current practice)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"averaging an array with np.mean is: \n",
    "      {for_loop_list_time/np_mean_matrix_time} times faster than averaging a list with for loop (my current practice)\"\"\")\n",
    "print(f\"\"\"averaging a list with np.mean is: \n",
    "      {for_loop_list_time/np_mean_list_time} times faster than averaging a list with for loop (my current practice)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that this part of `callback` can be sped up nearly four times! Now it feels almost obligatory to time the other parts as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing frame addition\n",
    "I am interested in seeing the difference between adding small and large integers. But first it is time for some general calculations: If I want at most 10 ms latency (as fast googling shows), then my callback has this time to execute. Sounddevice docs say *It is reasonable to expect to be able to utilise 70% or more of the available CPU time in the PortAudio callback.* So my callback has **7 ms** to execute, and the blocksize for 10 ms latency is 44100/100 = 441 samples per call.\n",
    "\n",
    "The callback will be called with frequency 100 Hz. Supposing a very long recording sesh would last one hour, the callback will be called 100*3600 = 360 000 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low: 0.0007239095003981219\n"
     ]
    }
   ],
   "source": [
    "low_setup=\"\"\"frames = 10\n",
    "curr_fr = 0\"\"\"\n",
    "adding = \"for i in range(100): curr_fr += frames\"\n",
    "low_times = timeit.repeat(stmt=adding, repeat=10000, number=100, setup=low_setup)\n",
    "print(f\"low: {sum(low_times)/len(low_times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high: 0.0008153054061997864\n"
     ]
    }
   ],
   "source": [
    "high_setup=\"\"\"frames = 10\n",
    "curr_fr = 10**20\"\"\"\n",
    "high_times = timeit.repeat(stmt=adding, repeat=10000, number=100, setup=high_setup)\n",
    "print(f\"high: {sum(high_times)/len(high_times)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if I recorded for 31 billion years, this piece of code would only use 8.153054061997864e-08 s per callback, which is approximately 0.00001 % of the callback time. No need to worry here. **But** I have forgotten that this is not the only place where frames are used! Lets test for this code snippet:\n",
    "```py\n",
    "start = _current_frame % len(track)\n",
    "end = (_current_frame+frames) % len(track)\n",
    "``` \n",
    "Self is not relevant and len(track) is constant (I do not suppose len would return very differently for very short and very long lists, might test that later), so it can be reduced to:\n",
    "```py\n",
    "start = current_frame % n\n",
    "end = (current_frame+frames) % n\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_setup = \"\"\"\n",
    "n = 44100*5\n",
    "frames = 100\n",
    "current_frame = 0\n",
    "\"\"\"\n",
    "high_setup = \"\"\"\n",
    "n = 44100*5\n",
    "frames = 100\n",
    "current_frame = 10**20\n",
    "\"\"\"\n",
    "snip = \"\"\"start = current_frame % n\n",
    "end = (current_frame+frames) % n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low: 0.1129516416001934\n",
      "high: 0.3304551569997784\n"
     ]
    }
   ],
   "source": [
    "low_times = timeit.repeat(stmt=snip, setup=low_setup)\n",
    "high_times = timeit.repeat(stmt=snip, setup=high_setup)\n",
    "print(f\"low: {sum(low_times)/len(low_times)}\")\n",
    "print(f\"high: {sum(high_times)/len(high_times)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be significantly worse! But actually in the worst case this is gonna be 3e-1*e-6 = 3e-7 s, thus this is neither a critical point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
