{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing ```04_record_loops``` using ```timeit``` module\n",
    "Firstly, lets initialize all the necessary variables, as that is not something I have to time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import numpy.typing as npt\n",
    "\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import threading\n",
    "import random\n",
    "import timeit\n",
    "\n",
    "\n",
    "SAMPLERATE = 44100  # [samples per second]\n",
    "BLOCKSIZE = 1000  # [samples]\n",
    "DTYPE = np.int16\n",
    "STR_DTYPE = \"int16\"\n",
    "CHANNELS = 2\n",
    "LATENCY = 0\n",
    "\n",
    "METRONOME_SAMPLE_PATH = \"lib/samples/metronome.wav\"\n",
    "\n",
    "recording = False\n",
    "stream_active = True\n",
    "\n",
    "tracks: list[npt.NDArray[DTYPE]] = []\n",
    "recorded_track: npt.NDArray[DTYPE] = np.empty(shape=(0, CHANNELS), dtype=DTYPE)\n",
    "current_frame = 0\n",
    "len_beat: int  # number of samples per beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is questionable whether some of these could be optimalised. E.g. using numpy array instead of list for ```tracks``` could be faster. However, different tracks need to differ in length and I do not know whether numpy allows this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets analyze the functions in the program. There are three groups of functions:\n",
    "- ```metronome_generator``` and ```initialize_metronome```, which execute before the body of the program,\n",
    "- ```input_checker``` and ```post_production```, which are executed in the input thread,\n",
    "-  ```main``` and ```callback```, which are executed in the thread which is processing audio.\n",
    "\n",
    "As the first ones do not need to be timed, lets execute them now so the other ones can use the metronome sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metronome_generator(bpm: int, path: str) -> npt.NDArray[DTYPE]:\n",
    "    global len_beat\n",
    "\n",
    "    sample: npt.NDArray[DTYPE]\n",
    "    sample, fs = sf.read(file=path, dtype=STR_DTYPE)\n",
    "\n",
    "    desired_len = int((60*fs)/bpm)\n",
    "    len_beat = desired_len\n",
    "\n",
    "    if len(sample) <= desired_len:\n",
    "        # rounding desired_len introduces a distortion of bpm\n",
    "        sample = np.concatenate(\n",
    "            (sample, np.zeros(shape=(desired_len-len(sample), CHANNELS), dtype=DTYPE)))\n",
    "    else:\n",
    "        sample = sample[:desired_len]\n",
    "\n",
    "    # adjust volume\n",
    "    sample = (sample/4).astype(dtype=DTYPE)\n",
    "\n",
    "    return sample\n",
    "\n",
    "\n",
    "def initialize_metronome() -> None:\n",
    "    global tracks\n",
    "    # initialize metronome\n",
    "    bpm = int(input(\"bpm: \"))\n",
    "    metronome = metronome_generator(bpm=bpm, path=METRONOME_SAMPLE_PATH)\n",
    "    tracks.append(metronome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other two groups run in the same thread, for python does not allow true parallelism, so it is necessary to optimalise both of them. Lets start with the audio processing, as I suppose it may require more CPU power and I also have some ideas for optimalisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    \"\"\" processes the audio \"\"\"\n",
    "    global stream_active\n",
    "\n",
    "    def callback(indata: npt.NDArray[DTYPE], outdata: npt.NDArray[DTYPE],\n",
    "                 frames: int, time: Any, status: sd.CallbackFlags) -> None:\n",
    "        global current_frame\n",
    "        global tracks\n",
    "        global recorded_track\n",
    "\n",
    "        if status:\n",
    "            print(status)\n",
    "\n",
    "        if recording:\n",
    "            recorded_track = np.concatenate([recorded_track, indata])\n",
    "\n",
    "        # mixer & slicer\n",
    "        num_tracks = len(tracks)\n",
    "        data = (indata/(num_tracks + 1)).astype(dtype=DTYPE)\n",
    "\n",
    "        for track in tracks:\n",
    "            # slice\n",
    "            start = current_frame % len(track)\n",
    "            end = (current_frame+frames) % len(track)\n",
    "            if end < start:\n",
    "                track_slice = np.concatenate(\n",
    "                    (track[start:], track[:end]))\n",
    "            else:\n",
    "                track_slice = track[start:end]\n",
    "            # mix\n",
    "            track_slice = (track_slice/(num_tracks+1)).astype(dtype=DTYPE)\n",
    "\n",
    "            data += track_slice\n",
    "\n",
    "        outdata[:] = data\n",
    "        current_frame += frames\n",
    "\n",
    "    try:\n",
    "        with sd.Stream(samplerate=SAMPLERATE, blocksize=BLOCKSIZE, dtype=STR_DTYPE,\n",
    "                       channels=CHANNELS, callback=callback):\n",
    "            while stream_active:\n",
    "                pass\n",
    "    finally:\n",
    "        print(\"Good bye!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas:\n",
    "- is using global variables slow?\n",
    "- the for loop is certainly inefficient -> use numpy.mean() for the mixing\n",
    "    - how to improve the cutting?\n",
    "- is the handling of large integers in ```current_frame``` okay?\n",
    "- is the while loop, which is keeping the stream active, draining CPU power? If yes, how to keep the stream alive without this drawback?\n",
    "\n",
    "First of all, mixing and cutting. Or just mixing, as it is a smaller piece of code. Lets initialize some track data, so we can test different approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN_TRACK = 100\n",
    "NUM_TRACKS = 10\n",
    "NUMBER = 1\n",
    "REPEAT = 10000\n",
    "\n",
    "def generate_random_track(length: int, channels: int = 2) -> npt.NDArray[DTYPE]:\n",
    "    return np.array([[random.randint(-2**15, 2**15-1), random.randint(-2**15, 2**15-1)] for i in range(length)])\n",
    "\n",
    "cut_tracks = np.array([generate_random_track(LEN_TRACK) for i in range(NUM_TRACKS)])\n",
    "\n",
    "for_loop = \"\"\"\n",
    "data = cut_tracks[0]\n",
    "for track_slice in cut_tracks:\n",
    "    track_slice = (track_slice/(NUM_TRACKS+1)).astype(dtype=DTYPE)\n",
    "    data += track_slice\"\"\"\n",
    "\n",
    "np_mean = \"\"\"\n",
    "data = np.mean(a=cut_tracks, axis=0)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can comparte those two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.mean was 0.0001221380002789374 second faster\n"
     ]
    }
   ],
   "source": [
    "for_loop_time = min(timeit.repeat(stmt=for_loop, number=NUMBER, repeat=REPEAT, globals=globals()))\n",
    "mean_time = min(timeit.repeat(stmt=np_mean, number=NUMBER, repeat=REPEAT, globals=globals()))\n",
    "\n",
    "difference = for_loop_time - mean_time\n",
    "if difference < 0:\n",
    "    print(f\"for loop was {difference*-1} second faster\")\n",
    "else:\n",
    "    print(f\"np.mean was {difference} second faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In january I have figured out that I store the recorded tracks in a `list` of `np.arrays`. I am wondering whether it would be faster to store them in a big `np.array`, so lets time it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_matrix = np.array([generate_random_track(length=LEN_TRACK) for i in range(NUM_TRACKS)])\n",
    "big_list = [generate_random_track(length=LEN_TRACK) for i in range(NUM_TRACKS)]\n",
    "\n",
    "# averaging a list with for loop\n",
    "for_loop_list = \"\"\"\n",
    "data = big_list[0]\n",
    "for track_slice in big_list:\n",
    "    track_slice = (track_slice/(NUM_TRACKS+1)).astype(dtype=DTYPE)\n",
    "    data += track_slice\n",
    "\"\"\"\n",
    "\n",
    "# averaging an array with for loop\n",
    "for_loop_matrix = \"\"\"\n",
    "data = np_matrix[0]\n",
    "for track_slice in np_matrix:\n",
    "    track_slice = (track_slice/(NUM_TRACKS+1)).astype(dtype=DTYPE)\n",
    "    data += track_slice\n",
    "\"\"\"\n",
    "\n",
    "# averaging a list with np.mean\n",
    "np_mean_list = \"\"\"\n",
    "data = np.mean(a=big_list, axis=0)\n",
    "\"\"\"\n",
    "\n",
    "# averaging an array with np.mean\n",
    "np_mean_matrix = \"\"\"\n",
    "data = np.mean(a=np_matrix, axis=0)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time of averaging a list with for loop:      0.00014885000018693972 s\n",
      "time of averaging an array with for loop:    0.00015808499983904767 s\n",
      "time of averaging a list with np.mean:       5.36659999852418e-05 s\n",
      "time of averaging an array with np.mean:     3.9323999772022944e-05 s\n"
     ]
    }
   ],
   "source": [
    "for_loop_list_time = min(timeit.repeat(stmt=for_loop_list, number=NUMBER, repeat=REPEAT, globals=globals()))\n",
    "for_loop_matrix_time = min(timeit.repeat(stmt=for_loop_matrix, number=NUMBER, repeat=REPEAT, globals=globals()))\n",
    "np_mean_list_time = min(timeit.repeat(stmt=np_mean_list, number=NUMBER, repeat=REPEAT, globals=globals()))\n",
    "np_mean_matrix_time = min(timeit.repeat(stmt=np_mean_matrix, number=NUMBER, repeat=REPEAT, globals=globals()))\n",
    "\n",
    "print(f\"time of averaging a list with for loop:      {for_loop_list_time} s\")\n",
    "print(f\"time of averaging an array with for loop:    {for_loop_matrix_time} s\")\n",
    "print(f\"time of averaging a list with np.mean:       {np_mean_list_time} s\")\n",
    "print(f\"time of averaging an array with np.mean:     {np_mean_matrix_time} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "averaging an array with np.mean is: \n",
      "      3.7852202484458117 times faster than averaging a list with for loop (my current practice)\n",
      "averaging a list with np.mean is: \n",
      "      2.7736369438354567 times faster than averaging a list with for loop (my current practice)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"averaging an array with np.mean is: \n",
    "      {for_loop_list_time/np_mean_matrix_time} times faster than averaging a list with for loop (my current practice)\"\"\")\n",
    "print(f\"\"\"averaging a list with np.mean is: \n",
    "      {for_loop_list_time/np_mean_list_time} times faster than averaging a list with for loop (my current practice)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that this part of `callback` can be sped up nearly four times! Now it feels almost obligatory to time the other parts as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
